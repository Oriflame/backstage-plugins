# Updating system-scores from sharepoint and uploading to azure storage
# should run periodically

parameters:
- name: agentPoolName
  displayName: 'Agent pool name'
  type: string
  default: 'Azure Pipelines'
  values:
  - Azure Pipelines # public cloud agents
  - 'TODO: add your own agent pool' # or delete this if you don't have any

trigger: none

# scheduled run: https://docs.microsoft.com/en-us/azure/devops/pipelines/process/scheduled-triggers?view=azure-devops&tabs=yaml
schedules:
- cron: "45 0,6,12,18 * * *"
  displayName: 'Every 6 hours at 45th minute' # example schedule
  branches:
    include:
    - main # TODO: change to your branch
  always: true

jobs:
- job:
  displayName: 'Integration job'
  pool:
    name: ${{ parameters.agentPoolName }}
  variables:
  - name: sourcePathForScoringData
    value: ./scoring-data # TODO: create folder with scoring data for your system/entities, see sample-data folder 
  - name: sharepointListId
    value: '12345678-1234-aaaa-bbbb-1234567890aa' # TODO: guid for your list containing answers
  - name: sharepointSiteURL
    value: 'https://yourOffice365Account.sharepoint.com/teams/some-site' # TODO: url of the Office365 site you want to itegrate against
  steps:
  - template: ./templates/checkout-branch-properly.yaml

  # get items from sharpeoint list and updates local files
  - task: AzureCLI@2.208.0
    displayName: 'Update system-scores from sharepoint'
    inputs:
      azureSubscription: BackstageCatalogSharepointIntegration # TODO: create the service connection, see documentation
      scriptType: pscore
      scriptLocation: scriptPath
      scriptPath: './scripts/Sync-Sharepoint.ps1'
      addSpnToEnvironment: true
      arguments:
        -action
        download
        -systemScoreFolder
        '$(sourcePathForScoringData)'
        -listId
        '$(sharepointListId)'
        -siteURL
        '$(sharepointSiteURL)'
      pwsh: true

  # always (e.g. during PR) upload also to DEV storage. if this would cause any issue (like overwriting data from regular main run over branch data), remove it 
  - task: AzureCLI@2.208.0
    displayName: 'Uploading to DEV storage'
    inputs:
      azureSubscription: BackstageCatalogSharepointIntegration
      scriptLocation: inlineScript
      inlineScript: |
        az storage blob upload-batch \
          --destination 'system-scores' \
          --account-name 'azureblobstorageaccount' \
          --source '$(sourcePathForScoringData)' \
          --pattern *.json \
          --auth-mode login \
          --overwrite
      # ^^^^ TODO fix account name, destination paths,...

  # when on MAIN branch upload to oribackstagedevpublic storage
  - task: AzureCLI@2.208.0
    displayName: 'Uploading to LIVE storage'
    inputs:
      azureSubscription: BackstageCatalogSharepointIntegration
      scriptLocation: inlineScript
      inlineScript: |
        az storage blob upload-batch \
          --destination 'system-scores' \
          --account-name 'azureblobstorageaccount' \
          --source '$(sourcePathForScoringData)' \
          --pattern *.json \
          --auth-mode login \
          --overwrite
      # ^^^^ TODO fix account name, destination paths,...
    condition: eq(variables['Build.SourceBranch'],'refs/heads/main') # TODO: fix branch name

  #commit&push changes
  - task: PowerShell@2.212.0
    displayName: 'Auto commit changes'
    inputs:
      filePath: './scripts/push-changes.ps1'
      arguments:
        -autogeneratedDefinitionsFolder
        '$(sourcePathForScoringData)'
        -outputFile
        '$(sourcePathForScoringData)/all.json'
      failOnStderr: true
      showWarnings: true
      pwsh: true
      workingDirectory: '$(Build.SourcesDirectory)/pipelines'
